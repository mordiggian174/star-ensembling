{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHES = 2 # Experiments were set for 30 or 10 epoches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQ9KxWEOQa8V"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KC1buI2cG8Wl"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R59EYNJ1QnXi"
   },
   "source": [
    "# Model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1P9GoDNehJsO"
   },
   "outputs": [],
   "source": [
    "class BaseNet(nn.Module):\n",
    "    '''\n",
    "    Base regression model\n",
    "    '''\n",
    "    def __init__(self, ini_bias=None):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "           nn.Linear(90, 120),\n",
    "           nn.BatchNorm1d(120),\n",
    "           nn.Dropout(0.2),\n",
    "           nn.ReLU(),\n",
    "           nn.Linear(120, 20),\n",
    "           nn.BatchNorm1d(20),\n",
    "           nn.Dropout(0.2),\n",
    "           nn.ReLU(),\n",
    "           nn.Linear(20, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z6HC6ziHUnnZ"
   },
   "outputs": [],
   "source": [
    "class StarRegression(nn.Module):\n",
    "    def __init__(self, trained_list, BaseClass, warmup=None, *args, **kwargs):\n",
    "        '''\n",
    "        Constructs Star aggregation of models\n",
    "        uses segments from empirical minimizers (trained models) via sigmoid\n",
    "\n",
    "        args:\n",
    "            trained_list - list of trained models (will be copied)\n",
    "            BaseClass - class of new model,\n",
    "                        which will be connected with trained_model\n",
    "                        and trained alongside weights of models (self.l)\n",
    "            *args, **kwargs - arguments for BaseClass initialization \n",
    "        '''\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.trained_models = nn.ModuleList()\n",
    "        for model in trained_list:\n",
    "            self.trained_models.append(copy.deepcopy(model))\n",
    "            for p in self.trained_models[-1].parameters():\n",
    "                p.requires_grad = False\n",
    "        if warmup is not None:\n",
    "            self.training_model = copy.deepcopy(warmup)\n",
    "            for p in self.training_model.parameters():\n",
    "                p.requires_grad = True\n",
    "        else:\n",
    "            self.training_model = BaseClass(*args, **kwargs)\n",
    "\n",
    "        self.weights = nn.Parameter(torch.zeros(len(trained_list)+1))\n",
    "        self.weights.requires_grad = True\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        outs = []\n",
    "        for model in self.trained_models:\n",
    "            outs.append(model(x))\n",
    "        outs.append(self.training_model(x))\n",
    "        return torch.stack(outs, -1) @ nn.functional.softmax(self.weights, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDfBPBcJaucA"
   },
   "outputs": [],
   "source": [
    "class ParallelRegression(nn.Module):\n",
    "    def __init__(self, BaseClass, model_num=2, *args, **kwargs):\n",
    "        '''\n",
    "        args:\n",
    "            BaseClass - class of models,\n",
    "                        which will be connected similarly to SegmentStarRegression\n",
    "                        but trained in parallel\n",
    "            model_num - number of base models\n",
    "            *args, **kwargs - arguments for BaseClass initialization\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.models = nn.ModuleList()\n",
    "        for _ in range(model_num):\n",
    "            self.models.append(BaseClass(*args, **kwargs))\n",
    "        self.linear = nn.Linear(model_num, 1, bias=True)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        outs = []\n",
    "        for model in self.models:\n",
    "            outs.append(model(x))\n",
    "        return self.linear(torch.stack(outs, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSgCxezhQd1V"
   },
   "source": [
    "# Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/YearPredictionMSD.txt', header=None)\n",
    "\n",
    "X = df.iloc[:, 1:].values\n",
    "y = df.iloc[:, 0].values\n",
    "\n",
    "train_size = 463715\n",
    "X_train = X[:train_size, :]\n",
    "y_train = y[:train_size]\n",
    "X_test = X[train_size:, :]\n",
    "y_test = y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DU_Yy26pPiHS"
   },
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "26b6a0c77af942eaaa746801fb3a566c",
      "56eecab378904496a0f39a4a0575a886",
      "78abf27d5e4643c6ba2bf0e4570c9ae1",
      "81da4bd986974a4583fc795fdca1afcc",
      "e1c5ace95b7549f3a3a6be4af3335441",
      "06ffe57a2c7840bfab7736754b1f00d6",
      "6b7c6cbb6381475a9888d83d7e402120",
      "a73c3cbe46814ec487d56935bde31aef",
      "4d0650ade7a342b9967dbae6a1fcd815",
      "985178ddc2204e32b763061205accb8e",
      "80e7e4a83ee14ac2b96ee970119b5278"
     ]
    },
    "id": "f_e_TyPZ-GbE",
    "outputId": "319e1676-c762-4945-8f75-c0a8d11a1d72"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = 0\n",
    "\n",
    "set_random_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 128\n",
    "MAX_D = 5\n",
    "NUM_EXPERIMENTS = 5\n",
    "\n",
    "\n",
    "features_scaler = StandardScaler()\n",
    "scaled_X_train = features_scaler.fit_transform(X_train)\n",
    "scaled_X_test  = features_scaler.transform(X_test)\n",
    "\n",
    "target_scaler = StandardScaler()\n",
    "scaled_y_train = target_scaler.fit_transform(y_train.reshape(-1, 1)).squeeze()\n",
    "scaled_y_test = target_scaler.transform(y_test.reshape(-1, 1)).squeeze()\n",
    "\n",
    "\n",
    "train_set = TensorDataset(torch.Tensor(scaled_X_train), torch.Tensor(scaled_y_train))\n",
    "train_dataloader = DataLoader(train_set, batch_size = batch_size, pin_memory=True, shuffle=True)\n",
    "\n",
    "test_set = TensorDataset(torch.Tensor(scaled_X_test), torch.Tensor(scaled_y_test))\n",
    "test_dataloader = DataLoader(test_set, batch_size = batch_size, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_SCALE = target_scaler.scale_[0]\n",
    "Y_SCALE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x2FpGzZkauj3"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_dataloader, criterion, optimizer, device='cpu'):\n",
    "    '''\n",
    "    Trains model for a single epoch\n",
    "    \n",
    "    Args:\n",
    "        model - model to be trained\n",
    "        train_dataloader - dataloader of training dataset\n",
    "        criterion - loss criterion\n",
    "        optimizer - optimizer\n",
    "        device - device to compute on\n",
    "    \n",
    "    returns:\n",
    "        average loss on training dataset\n",
    "    '''\n",
    "    model.train()\n",
    "\n",
    "    loss_sum = 0\n",
    "    acc_sum = 0\n",
    "    total = 0\n",
    "\n",
    "    for x, y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_pred = model(x).squeeze()\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss_sum += loss.item() * y.shape[0]\n",
    "        total += y.shape[0]\n",
    "\n",
    "    return loss_sum / total\n",
    "\n",
    "\n",
    "def train(model, train_dataloader, epoch_num, optimizer, scheduler=None,\n",
    "          device='cpu', plot_freq=2, y_scale=Y_SCALE, name=''):\n",
    "    '''\n",
    "    Trains model for given number of epoches\n",
    "    \n",
    "    Args:\n",
    "        model - model to be trained\n",
    "        train_dataloader - dataloader of training dataset\n",
    "        epoch_num - number of epoches to train\n",
    "        optimizer - optimizer\n",
    "        scheduler - optimizer scheduler\n",
    "        device - device to compute on\n",
    "        plot_freq - if int, graph is plotted every plot_freq epoches, else only loss is printed\n",
    "        y_scale - scale of targets\n",
    "        name - name of model\n",
    "    \n",
    "    returns:\n",
    "        losses - list of loss on training dataset\n",
    "        training time - total time spent on training\n",
    "    '''\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_losses = []\n",
    "    for epoch in range(epoch_num):\n",
    "        loss = train_one_epoch(model, train_dataloader, criterion, optimizer, device)\n",
    "        train_losses += [loss * y_scale**2]\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "            \n",
    "        if isinstance(plot_freq, int) and epoch % plot_freq == plot_freq-1:\n",
    "            fig, axs = plt.subplots(figsize=(8, 8))\n",
    "            axs.plot(range(len(train_losses)), train_losses)\n",
    "            axs.set(ylabel = 'MSE', xlabel='Epoch', title='Training Loss')\n",
    "            axs.legend()\n",
    "            \n",
    "            clear_output()\n",
    "            plt.show()\n",
    "            print(name, 'epoch number ', epoch, '\\n')\n",
    "            print('time training:', round(time.time() - start_time, 1), 'sec')\n",
    "            print('train loss:', np.sqrt(train_losses[-1]), '\\n\\n')\n",
    "\n",
    "    training_time = round(time.time() - start_time, 1)\n",
    "\n",
    "    return train_losses, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mse_mae(model_list, dataloader, y_scale=Y_SCALE, device='cpu'):\n",
    "    '''\n",
    "    Evaluates model on all objects in dataset\n",
    "    \n",
    "    Args:\n",
    "        model_list - model to be evaluated,\n",
    "                     if list of models - ensemble of these models will be evaluated\n",
    "        dataloader - dataloader of a dataset\n",
    "        y_scale - scale of targets\n",
    "        device - device to compute on\n",
    "    \n",
    "    returns:\n",
    "        mse_sum, mae_sum - average MSE and MAE on given dataset (scaled by y_scale)\n",
    "    '''\n",
    "    if not isinstance(model_list, list):\n",
    "        model_list = [model_list]\n",
    "    for model in model_list:\n",
    "        model.eval()\n",
    "\n",
    "    mse_sum = 0\n",
    "    mae_sum = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model_list[0](x).squeeze()\n",
    "            for model in model_list[1:]:\n",
    "                y_pred += model(x).squeeze()\n",
    "            y_pred /= len(model_list)\n",
    "\n",
    "            mse_sum += torch.sum((y_pred - y)**2).item()\n",
    "            mae_sum += torch.sum(torch.abs(y_pred - y)).item()\n",
    "            total += y.shape[0]\n",
    "    \n",
    "    mse_sum *= y_scale**2 / total\n",
    "    mae_sum *= y_scale / total\n",
    "\n",
    "    return mse_sum, mae_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snap_train_one_epoch(model, train_dataloader, criterion, optimizer, scheduler=None, device='cpu'):\n",
    "    '''\n",
    "    Trains model for a single epoch via snapshot technique\n",
    "    \n",
    "    Args:\n",
    "        model - model to be trained\n",
    "        train_dataloader - dataloader of training dataset\n",
    "        criterion - loss criterion\n",
    "        optimizer - optimizer\n",
    "        device - device to compute on\n",
    "    \n",
    "    returns:\n",
    "        average loss on training dataset\n",
    "    '''\n",
    "    model.train()\n",
    "\n",
    "    loss_sum = 0\n",
    "    total = 0\n",
    "\n",
    "    for x, y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_pred = model(x).squeeze()\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss_sum += loss.item() * y.shape[0]\n",
    "        total += y.shape[0]\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "            \n",
    "    return loss_sum / total\n",
    "\n",
    "\n",
    "def snapshot_train(model, train_dataloader, epoch_num, device='cpu',\n",
    "                   snap_freq=EPOCHES, plot_freq=2, scale=Y_SCALE, name=None):\n",
    "    ''' \n",
    "    Trains model for given number of epoches via snapshot technique\n",
    "    \n",
    "    args:\n",
    "        model - model to be trained\n",
    "        train_dataloader - dataloader of training dataset\n",
    "        epoch_num - amount of epoches to train\n",
    "        device - device to compute on\n",
    "        snap_freq - length of iteration of snapshot cycle (in epoches)\n",
    "        plot_freq - if int, graph is plotted every plot_freq epoches, else only loss is printed\n",
    "        y_scale - scale of targets\n",
    "        name - name of model\n",
    "    \n",
    "    returns:\n",
    "        snapshots - list containing copies of snapshots\n",
    "        losses - list of losses on training dataset\n",
    "        training time - list of times spent on training for each snapshot\n",
    "    '''\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_losses = []\n",
    "    \n",
    "    snapshots = []\n",
    "    snap_times = []\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_dataloader) * snap_freq)\n",
    "\n",
    "    for epoch in range(epoch_num):\n",
    "        loss = snap_train_one_epoch(model, train_dataloader, criterion, optimizer, scheduler, device)\n",
    "        train_losses += [loss * scale**2]\n",
    "            \n",
    "        if epoch % snap_freq == snap_freq - 1:\n",
    "            snapshots += [copy.deepcopy(model)]\n",
    "            snap_times += [round(time.time() - start_time)]\n",
    "\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_dataloader) * snap_freq)\n",
    "\n",
    "\n",
    "        if isinstance(plot_freq, int) and epoch % plot_freq == plot_freq - 1:\n",
    "            fig, axs = plt.subplots(figsize=(8, 8))\n",
    "            axs.plot(range(len(train_losses)), train_losses)\n",
    "            axs.set(ylabel = 'MSE', xlabel='Epoch', title='Training Loss')\n",
    "            axs.legend()\n",
    "            \n",
    "            clear_output()\n",
    "            plt.show()\n",
    "            print(name, 'epoch number ', epoch, '\\n')\n",
    "            print('time training:', round(time.time() - start_time, 1), 'sec')\n",
    "            print('train loss:', np.sqrt(train_losses[-1]), '\\n\\n')\n",
    "\n",
    "    return snapshots, train_losses, np.array(snap_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "juditG5HsunV"
   },
   "outputs": [],
   "source": [
    "def add_res(results, name, add_row):\n",
    "    '''\n",
    "    Adds new row with index \"name\" to DataFrame\n",
    "    Args:\n",
    "        results -  pd.DataFrame containing results for all models\n",
    "        name - name of new row\n",
    "        add_row - row which will be added\n",
    "    '''\n",
    "    if name not in results.index:\n",
    "        results.loc[name] = add_row\n",
    "        return\n",
    "\n",
    "    res_row = []\n",
    "    for i, col in enumerate(results):\n",
    "        res_row += [results.loc[name,col] + add_row[i]]\n",
    "    results.loc[name] = res_row\n",
    "\n",
    "\n",
    "def make_experiment(results, model_class=BaseNet, epoches=EPOCHES, base_am=MAX_D, warmup_epoches=EPOCHES//10):\n",
    "    '''\n",
    "    Run an experiment for non-snapshot classes\n",
    "    Args:\n",
    "        results - pd.DataFrame containing results for all models\n",
    "        model_class - Class for each base block\n",
    "        epoches - total number of epoches for each step of algorithm\n",
    "        base_am - maximum d (there will be total of base_am + 1 blocks)\n",
    "        warm_up_epoches - number of epoches for warm-up\n",
    "    returns:\n",
    "        results - changed pd.DataFrame containing old and new results\n",
    "    '''\n",
    "\n",
    "    bases = []\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    ensemble_times = []\n",
    "    scheduler = None\n",
    "    \n",
    "    for i in range(base_am+1):\n",
    "        bases.append(model_class())\n",
    "        bases[i].to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(bases[i].parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "        losses, time = train(bases[i], train_dataloader, epoches,\n",
    "                             optimizer, device=device, name=\"base model \" + str(i+1))\n",
    "    \n",
    "        if len(ensemble_times):\n",
    "            ensemble_times += [ensemble_times[-1] + time]\n",
    "        else:\n",
    "            ensemble_times += [time]\n",
    "\n",
    "        mse, mae = get_mse_mae(bases[i], test_dataloader, Y_SCALE, device)\n",
    "        \n",
    "        add_res(results, 'Big NN 0', [[mse], [mae], [losses[-1]], [time]])\n",
    "    \n",
    "    # ensemble -----------------------------------------------------------------\n",
    "\n",
    "    for i in range(base_am):\n",
    "        mse, mae = get_mse_mae(bases[:i+2], test_dataloader, Y_SCALE, device)\n",
    "        train_mse, train_mae = get_mse_mae(bases[:i+2], train_dataloader, Y_SCALE, device)\n",
    "            \n",
    "        add_res(results, 'Ensemble ' + str(i+1), [[mse], [mae], [train_mse], [ensemble_times[i+1]]])\n",
    "\n",
    "    # star ---------------------------------------------------------------------\n",
    "\n",
    "    star_models = []\n",
    "\n",
    "    for i in range(base_am):\n",
    "        name = 'Classic Star (no warm-up) ' + str(i+1)\n",
    "        star = StarRegression(bases[:i+1], model_class).to(device)\n",
    "        optimizer = torch.optim.Adam(star.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "        \n",
    "        losses, time = train(star, train_dataloader, epoches, optimizer, device=device, name=name)\n",
    "\n",
    "        mse, mae = get_mse_mae(star, test_dataloader, Y_SCALE, device)\n",
    "            \n",
    "        add_res(results, name, [[mse], [mae], [losses[-1]], [time + ensemble_times[i]]])\n",
    "  \n",
    "\n",
    "    # warmup star ---------------------------------------------------------------------\n",
    "\n",
    "    warmed = model_class().to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(warmed.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "    _, warmup_time = train(warmed, train_dataloader, warmup_epoches,\n",
    "                           optimizer, device=device, name='warmup')\n",
    "\n",
    "    for i in range(base_am):\n",
    "        name = 'Classic Star (new warm-up) ' + str(i+1)\n",
    "        star = StarRegression(bases[:i+1], model_class, warmup=warmed).to(device)\n",
    "        optimizer = torch.optim.Adam(star.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "        \n",
    "        losses, time = train(star, train_dataloader, epoches - warmup_epoches, optimizer, device=device, name=name)\n",
    "\n",
    "        mse, mae = get_mse_mae(star, test_dataloader, Y_SCALE, device)\n",
    "            \n",
    "        add_res(results, name, [[mse], [mae], [losses[-1]], [time + warmup_time + ensemble_times[i]]])\n",
    "\n",
    "\n",
    "    # parallel -----------------------------------------------------------------\n",
    "\n",
    "    parallel_models = []\n",
    "\n",
    "    for i in range(base_am):\n",
    "        name = 'Big NN ' + str(i+1)\n",
    "        parallel_model = ParallelRegression(model_class, i+2).to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(parallel_model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "        \n",
    "        losses, time = train(parallel_model, train_dataloader, epoches, optimizer, device=device, name=name)\n",
    "\n",
    "        mse, mae = get_mse_mae(parallel_model, test_dataloader, Y_SCALE, device)\n",
    "        \n",
    "        add_res(results, name, [[mse], [mae], [losses[-1]], [time]])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_snapshot_experiment(results, model_class=BaseNet, epoches=EPOCHES, base_am=MAX_D, warmup_epoches=EPOCHES//10):\n",
    "    '''\n",
    "    Run an experiment for snapshot classes\n",
    "    Args:\n",
    "        results - pd.DataFrame containing results for all models\n",
    "        model_class - Class for each base block\n",
    "        epoches - total number of epoches for each step of algorithm\n",
    "        base_am - maximum d (there will be total of base_am + 1 blocks)\n",
    "        warm_up_epoches - number of epoches for warm-up\n",
    "    returns:\n",
    "        results - changed pd.DataFrame containing old and new results\n",
    "    '''\n",
    "\n",
    "    base = model_class().to(device)\n",
    "    snapshots, losses, cum_times = snapshot_train(base, train_dataloader, epoches*(base_am+1),\n",
    "                                                  device=device, snap_freq=epoches, name='snapshot')\n",
    "    \n",
    "    snap_times = cum_times.copy()\n",
    "    snap_times[1:] = np.diff(cum_times)\n",
    "        \n",
    "    for i in range(len(snapshots)):\n",
    "        snapshots[i].to(device)\n",
    "        mse, mae = get_mse_mae(snapshots[i], test_dataloader, Y_SCALE, device)\n",
    "        add_res(results, 'Snap Ensemble 0', [[mse], [mae], [losses[-1]], [snap_times[i]]])    \n",
    "    \n",
    "\n",
    "    # ensemble -----------------------------------------------------------------\n",
    "    \n",
    "    for i in range(base_am):\n",
    "        mse, mae = get_mse_mae(snapshots[:i+2], test_dataloader, Y_SCALE, device)\n",
    "        train_mse, train_mae = get_mse_mae(snapshots[:i+2], train_dataloader, Y_SCALE, device)\n",
    "            \n",
    "        add_res(results, 'Snap Ensemble ' + str(i+1), [[mse], [mae], [train_mse], [cum_times[i+1]]])\n",
    "\n",
    "    # star ---------------------------------------------------------------------\n",
    "\n",
    "    star_models = []\n",
    "\n",
    "    for i in range(base_am):\n",
    "        name = 'Snap Star (no warm-up) ' + str(i+1)\n",
    "        star = StarRegression(snapshots[:i+1], model_class).to(device)\n",
    "        optimizer = torch.optim.Adam(star.parameters(), lr=1e-3, weight_decay=1e-3)\n",
    "        \n",
    "        losses, time = train(star, train_dataloader, epoches, optimizer,device=device, name=name)\n",
    "\n",
    "        mse, mae = get_mse_mae(star, test_dataloader, Y_SCALE, device)\n",
    "            \n",
    "        add_res(results, name, [[mse], [mae], [losses[-1]], [time + cum_times[i]]])\n",
    "  \n",
    "\n",
    "    # warmup star ---------------------------------------------------------------------\n",
    "\n",
    "    warmed = model_class().to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(warmed.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    _, warmup_time = train(warmed, train_dataloader, warmup_epoches, optimizer, device=device, name='warmup')\n",
    "\n",
    "    for i in range(base_am):\n",
    "        name = 'Snap Star (new warm-up) ' + str(i+1)\n",
    "        star = StarRegression(snapshots[:i+1], model_class, warmup=warmed).to(device)\n",
    "        optimizer = torch.optim.Adam(star.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "        scheduler=None\n",
    "        \n",
    "        losses, time = train(star, train_dataloader, epoches - warmup_epoches,\n",
    "                optimizer, device=device, name=name)\n",
    "\n",
    "        mse, mae = get_mse_mae(star, test_dataloader, Y_SCALE, device)\n",
    "            \n",
    "        add_res(results, name, [[mse], [mae], [losses[-1]], [time + warmup_time + cum_times[i]]])\n",
    "\n",
    "\n",
    "    # snap warmup star ---------------------------------------------------------------------\n",
    "\n",
    "    warmed = model_class().to(device)\n",
    "\n",
    "    for i in range(base_am):\n",
    "        name = 'Snap Star (shot warm-up) ' + str(i+1)\n",
    "        star = StarRegression(snapshots[:i+1], model_class, warmup=snapshots[i]).to(device)\n",
    "        optimizer = torch.optim.Adam(star.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "        scheduler=None\n",
    "        \n",
    "        losses, time = train(star, train_dataloader, epoches, optimizer, device=device, name=name)\n",
    "\n",
    "        mse, mae = get_mse_mae(star, test_dataloader, Y_SCALE, device)\n",
    "            \n",
    "        add_res(results, name, [[mse], [mae], [losses[-1]], [time + cum_times[i]]])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "apoiJUvUyBns",
    "outputId": "f88ffdcd-05de-4465-a79a-e8f17c363975",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "set_random_seed(SEED)\n",
    "results = pd.DataFrame({'MSE' : [], 'MAE' : [], 'Train MSE' : [], 'Time' : []})\n",
    "for i in range(NUM_EXPERIMENTS):\n",
    "    results = make_experiment(results,  warmup_epoches=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(SEED)\n",
    "for i in range(NUM_EXPERIMENTS):\n",
    "    results = make_snapshot_experiment(results, warmup_epoches=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results.to_csv(f'MSD {EPOCHES} epoch raw results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAR = (np.std(scaled_y_train)*Y_SCALE)**2\n",
    "print('Sample variance (for R2 score):', VAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.drop('Snap Star (no warm-up)1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating result table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in results.index:\n",
    "    d = idx.rsplit(' ', 1)[1]\n",
    "    results.loc[idx, 'd'] = d \n",
    "\n",
    "results.sort_values(by='d', inplace=True, ascending=False)\n",
    "\n",
    "converted_list = []\n",
    "\n",
    "for idx in results.index:\n",
    "    name = idx.rsplit(' ', 1)[0]\n",
    "    mean_mse = np.mean(results.loc[idx, 'MSE'])\n",
    "    std_mse = np.std(results.loc[idx, 'MSE'])\n",
    "    train_mse = np.mean(results.loc[idx, 'Train MSE'])\n",
    "    mae = np.mean(results.loc[idx, 'MAE'])\n",
    "    time = np.mean(results.loc[idx, 'Time'])\n",
    "    d = int(results.loc[idx, 'd'])\n",
    "\n",
    "    \n",
    "    converted_list.append([name, d, str(np.round(mean_mse, 2)) + ' ± ' + str(np.round(std_mse, 2)),\n",
    "                       np.round(mae, 2), np.round(1 - (mean_mse / VAR), 3), np.round(train_mse, 2), round(time)])\n",
    "\n",
    "\n",
    "converted_results = pd.DataFrame(converted_list, \n",
    "        columns=['model', 'd', 'MSE', 'MAE', 'R2', 'TRAIN MSE', 'TIME (sec)'])\n",
    "\n",
    "converted_results.to_csv(f'MSD {EPOCHES} epoch results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "cQrmQXCPCVLB"
   ],
   "name": "CifarStarAlgorithm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06ffe57a2c7840bfab7736754b1f00d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "26b6a0c77af942eaaa746801fb3a566c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_78abf27d5e4643c6ba2bf0e4570c9ae1",
       "IPY_MODEL_81da4bd986974a4583fc795fdca1afcc",
       "IPY_MODEL_e1c5ace95b7549f3a3a6be4af3335441"
      ],
      "layout": "IPY_MODEL_56eecab378904496a0f39a4a0575a886"
     }
    },
    "4d0650ade7a342b9967dbae6a1fcd815": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56eecab378904496a0f39a4a0575a886": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b7c6cbb6381475a9888d83d7e402120": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78abf27d5e4643c6ba2bf0e4570c9ae1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b7c6cbb6381475a9888d83d7e402120",
      "placeholder": "​",
      "style": "IPY_MODEL_06ffe57a2c7840bfab7736754b1f00d6",
      "value": ""
     }
    },
    "80e7e4a83ee14ac2b96ee970119b5278": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81da4bd986974a4583fc795fdca1afcc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d0650ade7a342b9967dbae6a1fcd815",
      "max": 169001437,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a73c3cbe46814ec487d56935bde31aef",
      "value": 169001437
     }
    },
    "985178ddc2204e32b763061205accb8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a73c3cbe46814ec487d56935bde31aef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e1c5ace95b7549f3a3a6be4af3335441": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_80e7e4a83ee14ac2b96ee970119b5278",
      "placeholder": "​",
      "style": "IPY_MODEL_985178ddc2204e32b763061205accb8e",
      "value": " 169001984/? [00:03&lt;00:00, 60048289.08it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
